{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSW84neQ4PdR"
      },
      "source": [
        "# Bag of Words\n",
        "\n",
        "En este notebook vamos a ver un ejemplo práctico de la técnica de \"Bag of Words\".\n",
        "\n",
        "Como hemos visto, cuando operamos con textos, no hay ninguna operación matemática definida que pueda trabajar con ellos directamente. Por ejemplo, no podemos combinar las palabras _\"hola\"_ y _\"adiós\"_. \n",
        "\n",
        "Por lo tanto, para poder utilizar textos definidos en lenguaje natural, independientemente del idioma utilizado, necesitamos **transformar estos textos en vectores numéricos** que los representen.\n",
        "\n",
        "La técnica más conocida para hacer esta transformación se llama ***bolsa de palabras*** o **Bag of Words**. \n",
        "\n",
        "Veamos cómo funciona con un ejemplo. Supongamos que tenemos el siguiente texto\n",
        "\n",
        "> *El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.* — Yoda a Anakin en el Consejo Jedi.\n",
        "\n",
        "El primer paso que debemos realizar es la limpieza del dataset de caracteres extraños y homogeneizarlo a minúsculas:\n",
        "\n",
        "> el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n",
        "\n",
        "Después, procederemos con la **tokenización**, que consiste en transformar el texto anterior en una matriz de palabras. \n",
        "\n",
        "Es decir, vamos a separar cada una de las palabras que componen la frase anterior utilizando espacios separadores. Por tanto, obtendríamos la siguiente lista de *tokens*:\n",
        "\n",
        "`['el', 'miedo', 'es', 'el', 'camino, 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']`.\n",
        "\n",
        "A partir de la lista anterior podemos construir un **diccionario** que contenga todas las palabras definidas en nuestro vocabulario. \n",
        "\n",
        "Entendemos por \"nuestro vocabulario\" las palabras que aparecen en los textos que estamos analizando. Así, analizando los *tokens* anteriores construiremos el siguiente diccionario:\n",
        "\n",
        "`['el', 'miedo', 'es', 'camino, 'hacia', 'lado', 'oscuro', 'lleva', 'a', 'la', 'ira', 'al', 'odio', 'sufrimiento', 'percibo', 'mucho', 'en', 'ti']`\n",
        "\n",
        "Por último, tenemos que transformar el texto original en un vector numérico de forma que las posiciones del vector representen las posiciones de las palabras del diccionario y los valores del vector representen el número de apariciones de la palabra del diccionario en el texto analizado. \n",
        "\n",
        "Dado que nuestro diccionario consta de 18 palabras, nuestro texto quedaría definido por el siguiente vector\n",
        "\n",
        "`[5, 3, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1]`\n",
        "\n",
        "Viéndolo en formato tabla es más fácil de detectar:\n",
        "\n",
        "| | el | miedo | es | camino | hacia | lado | oscuro | lleva | a | la | ira | al | odio | sufrimiento | percibo | mucho | en | ti |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| Frecuencia | 5 | 3 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 2 | 2 | 2 | 2 | 1 | 1 | 1 | 1 | 1 |\n",
        "\n",
        "Analizándolo vemos que la palabra *'miedo'* se repite 3 veces, la palabra *'ira'* 2, la palabra *'el'* 5, y así sucesivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d0cwDCs8LlP"
      },
      "source": [
        "En este caso hemos dejado la limpieza de las stop-words para después, pues nos interesaba ver el cambio entre el antes y el después.\n",
        "\n",
        "Si eliminaramos las stop-words veríamos que desparecen los artículos, determinantes, preposiciones, etc.\n",
        "\n",
        "En lugar de hacerlo manualmente, como hasta ahora, vamos a hacerlo con Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj4TXhJy5Oo5"
      },
      "source": [
        "La forma más rápida de hacerlo es utilizando el objeto `CountVectorizer` del paquete `feature_extraction.text` de la librería `scikit-learn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.029322Z",
          "start_time": "2020-03-02T13:43:38.865734Z"
        },
        "id": "QzzEeRLsFxyS"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.038618Z",
          "start_time": "2020-03-02T13:43:39.030666Z"
        },
        "id": "O4_vzJSlU68R"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.043934Z",
          "start_time": "2020-03-02T13:43:39.040135Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkeG7G2VHRx",
        "outputId": "5f730340-21d5-4f93-f1c7-eca727345472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "corpus = [\n",
        "    \"El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.\"\n",
        "]\n",
        "\n",
        "X = count_vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(X.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2JPvuPCVEs9"
      },
      "source": [
        "Podemos ver el mapeo mediante la función `get_feature_names_out()`. Como podéis observar, ésta función detecta los símbolos de puntuación y los ignora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-02T13:43:39.052240Z",
          "start_time": "2020-03-02T13:43:39.049943Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUXOKN5eWP9H",
        "outputId": "29a4036b-8ddf-4994-9720-5c99d30f9b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n",
            " 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLCdq7vX9DPG"
      },
      "source": [
        "Veamos ahora si elimináramos las stop-words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLlSPoPWIZkL",
        "outputId": "78942afd-ca0c-47cb-9a96-e79e3ba2f3a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo pip install -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IypXswWNU9HT",
        "outputId": "c6f80df8-f611-4b80-9d55-23d6d200b26a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXJ4tIRR9jSQ"
      },
      "source": [
        "En este caso, es necesario limpiar el dataset y homogeneizar a minusculas antes de usar `nltk`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4mYsq2LTZ7c",
        "outputId": "bf8f2c0a-ea70-441d-a84a-2640546ae37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zz8eWS4UCf4",
        "outputId": "e280e9ae-955f-4521-adc0-16eef749b770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~“”¡¿\n"
          ]
        }
      ],
      "source": [
        "# añadimos algunos más que no están en string.punctuation, como las comillas y \n",
        "# las aperturas de interrogación/exclamación\n",
        "# si no los añadiésemos, no se eliminarían\n",
        "chars = string.punctuation + '“”¡¿'\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dntEu4LYTiDL",
        "outputId": "3dabe65c-0340-4c60-9386-c718d45c8c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El miedo es el camino hacia el Lado Oscuro El miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento Percibo mucho miedo en ti\n"
          ]
        }
      ],
      "source": [
        "re_punc = re.compile('[%s]' % re.escape(chars))\n",
        "# eliminar la puntuación de cada palabra\n",
        "texto = re_punc.sub('', corpus[0])\n",
        "print(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpHXy9LaHt18"
      },
      "source": [
        "Convertimos el texto a minúsculas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8nsuU31ISMD",
        "outputId": "d3aa5588-aefa-44ca-bfff-7eca8526281e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n"
          ]
        }
      ],
      "source": [
        "texto = texto.lower()\n",
        "print(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDc8TzzewziV",
        "outputId": "1bdd9fe1-d03a-464c-81f2-57f127cb5a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['el', 'miedo', 'es', 'el', 'camino', 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']\n"
          ]
        }
      ],
      "source": [
        "stop_words = stopwords.words('spanish')\n",
        "palabras = texto.split(' ')\n",
        "print(palabras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SZiAtvf-DE6"
      },
      "source": [
        "Eliminamos las stop-words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSyfyWO79dc5",
        "outputId": "f2acea00-ceb8-45b8-ae58-1b5b53e9988d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['miedo', 'camino', 'hacia', 'lado', 'oscuro', 'miedo', 'lleva', 'ira', 'ira', 'lleva', 'odio', 'odio', 'lleva', 'sufrimiento', 'percibo', 'miedo']\n"
          ]
        }
      ],
      "source": [
        "palabras_limpias = [p for p in palabras if p not in stop_words]\n",
        "print(palabras_limpias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvWLiMSv-njd"
      },
      "source": [
        "Unimos el texto de nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSXYC4OS-ouF",
        "outputId": "81ed6dbc-2f11-4aae-e434-c692a4429bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "miedo camino hacia lado oscuro miedo lleva ira ira lleva odio odio lleva sufrimiento percibo miedo\n"
          ]
        }
      ],
      "source": [
        "texto_limpio = ' '.join(palabras_limpias)\n",
        "print(texto_limpio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8iAu8pg-FUX"
      },
      "source": [
        "Y aplicamos la técnica de Bag of Words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1L7-zyg-IhC",
        "outputId": "1a58e2e9-b6ba-41fc-8eac-d70cd3cbc103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 2 1 3 3 2 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform([texto_limpio])\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq6UTNu7-dBT",
        "outputId": "6278898a-8738-47e0-f204-03a4afae9fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['camino' 'hacia' 'ira' 'lado' 'lleva' 'miedo' 'odio' 'oscuro' 'percibo'\n",
            " 'sufrimiento']\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHYW85bn-yvX"
      },
      "source": [
        "Comparadlo con la versión sin limpiar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4h-fv92-4K8",
        "outputId": "27efa0d1-61af-4c5f-89f4-e778aa689052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7KUBXAP-4K_",
        "outputId": "9693607e-a5e7-4c27-a77f-913323d1729e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n",
            " 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxiWIveA88_K"
      },
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente texto:\n",
        "\n",
        "> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4lQuM5Xn_X0L"
      },
      "outputs": [],
      "source": [
        "corpus1 = ['¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bqjdjkj_fbD",
        "outputId": "b0300c6e-bae1-4560-a871-09f215982b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Qué es el honor comparado con el amor de una mujer Qué es el deber comparado con el calor de un hijo recién nacido entre los brazos o el recuerdo de la sonrisa de un hermano Aire y palabras Aire y palabras Solo somos humanos y los dioses nos hicieron para el amor Es nuestra mayor gloria y nuestra peor tragedia\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "\n",
        "import unidecode\n",
        "\n",
        "re_punc = re.compile('[%s]' % re.escape(chars))\n",
        "# eliminar la puntuación de cada palabra\n",
        "texto = re_punc.sub('', corpus1[0])\n",
        "print(texto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcbeNYO1sIdZ",
        "outputId": "f873fd3d-bf4e-4147-dc31-a7a827443d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qué es el honor comparado con el amor de una mujer qué es el deber comparado con el calor de un hijo recién nacido entre los brazos o el recuerdo de la sonrisa de un hermano aire y palabras aire y palabras solo somos humanos y los dioses nos hicieron para el amor es nuestra mayor gloria y nuestra peor tragedia\n"
          ]
        }
      ],
      "source": [
        "#Convertimos a minusculas\n",
        "texto = texto.lower()\n",
        "print(texto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAGFP26JsJyB",
        "outputId": "8a73fa3b-aaf9-4b58-9e4f-23da4f065f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "que es el honor comparado con el amor de una mujer que es el deber comparado con el calor de un hijo recien nacido entre los brazos o el recuerdo de la sonrisa de un hermano aire y palabras aire y palabras solo somos humanos y los dioses nos hicieron para el amor es nuestra mayor gloria y nuestra peor tragedia\n"
          ]
        }
      ],
      "source": [
        "#Eliminar acentos\n",
        "texto1 = unidecode.unidecode(texto)\n",
        "\n",
        "print(texto1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mRgguA_sLEU",
        "outputId": "d721f4ae-bc3e-45b9-a991-d2d7fc69dd5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['que', 'es', 'el', 'honor', 'comparado', 'con', 'el', 'amor', 'de', 'una', 'mujer', 'que', 'es', 'el', 'deber', 'comparado', 'con', 'el', 'calor', 'de', 'un', 'hijo', 'recien', 'nacido', 'entre', 'los', 'brazos', 'o', 'el', 'recuerdo', 'de', 'la', 'sonrisa', 'de', 'un', 'hermano', 'aire', 'y', 'palabras', 'aire', 'y', 'palabras', 'solo', 'somos', 'humanos', 'y', 'los', 'dioses', 'nos', 'hicieron', 'para', 'el', 'amor', 'es', 'nuestra', 'mayor', 'gloria', 'y', 'nuestra', 'peor', 'tragedia']\n",
            "['honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia']\n"
          ]
        }
      ],
      "source": [
        "#Eliminamos las stop-words:\n",
        "stop_words = stopwords.words('spanish')\n",
        "palabras = texto1.split(' ')\n",
        "print(palabras)\n",
        "\n",
        "palabras_limpias = [p for p in palabras if p not in stop_words]\n",
        "print(palabras_limpias)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYI_txYcsMay",
        "outputId": "82bda8e7-f251-49a1-cdb5-0e06ec54be12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "honor comparado amor mujer deber comparado calor hijo recien nacido brazos recuerdo sonrisa hermano aire palabras aire palabras solo humanos dioses hicieron amor mayor gloria peor tragedia\n"
          ]
        }
      ],
      "source": [
        "#Unimos el texto\n",
        "texto_limpio = ' '.join(palabras_limpias)\n",
        "print(texto_limpio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQdtEqCLsQmd",
        "outputId": "287e646a-ab99-4f24-d29d-34b18a0e42fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "#Bag of words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform([texto_limpio])\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pffLT7h2sYxI",
        "outputId": "9136fffe-d9fc-4dd3-da6d-9b4e6795c113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aire' 'amor' 'brazos' 'calor' 'comparado' 'deber' 'dioses' 'gloria'\n",
            " 'hermano' 'hicieron' 'hijo' 'honor' 'humanos' 'mayor' 'mujer' 'nacido'\n",
            " 'palabras' 'peor' 'recien' 'recuerdo' 'solo' 'sonrisa' 'tragedia']\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rWIR9XACDvM"
      },
      "source": [
        "### Ejercicio 2\n",
        "\n",
        "Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente *corpus* de documentos:\n",
        "\n",
        "> \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\" - Cersei Lannister\n",
        "\n",
        "> \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\" - Tyrion Lannister\n",
        "\n",
        "> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos\n",
        "\n",
        "> \"El hombre que dicta la condena debe blandir la espada.\" - Eddard Stark\n",
        "\n",
        "> \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\" - Lord Varys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqug2lmKCDvO",
        "outputId": "3ae87836-cbdb-488c-a9a4-676cd17c15b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ganar' 'juega' 'juego' 'morir' 'puede' 'solo' 'tronos']\n",
            "['construye' 'cuanto' 'hombre' 'inmediatamente' 'lado' 'muro' 'quiere'\n",
            " 'saber' 'sera' 'vecino']\n",
            "['aire' 'amor' 'brazos' 'calor' 'comparado' 'deber' 'dioses' 'gloria'\n",
            " 'hermano' 'hicieron' 'hijo' 'honor' 'humanos' 'mayor' 'mujer' 'nacido'\n",
            " 'palabras' 'peor' 'recien' 'recuerdo' 'solo' 'sonrisa' 'tragedia']\n",
            "['blandir' 'condena' 'debe' 'dicta' 'espada' 'hombre']\n",
            "['creen' 'grande' 'hombre' 'hombres' 'pared' 'pequeno' 'poder' 'proyectar'\n",
            " 'puede' 'reside' 'sombra' 'truco']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus2 = [\n",
        "    \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\",\n",
        "    \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\",\n",
        "    \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\",\n",
        "    \"El hombre que dicta la condena debe blandir la espada.\",\n",
        "    \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\"\n",
        "]\n",
        "\n",
        "for i in corpus2:\n",
        "  re_punc = re.compile('[%s]' % re.escape(chars))\n",
        "  # eliminar la puntuación de cada palabra\n",
        "  texto = re_punc.sub('', i)\n",
        "  #print(texto)\n",
        "  #Convertimos a minusculas\n",
        "  texto = texto.lower()\n",
        "  #print(texto)\n",
        "  texto1 = unidecode.unidecode(texto)\n",
        "  stop_words = stopwords.words('spanish')\n",
        "  palabras = texto1.split(' ')\n",
        "  #print(palabras)\n",
        "\n",
        "  palabras_limpias = [p for p in palabras if p not in stop_words]\n",
        "  #print(palabras_limpias)\n",
        "\n",
        "  texto_limpio = ' '.join(palabras_limpias)\n",
        "\n",
        "  \n",
        "  count_vectorizer = CountVectorizer()\n",
        "\n",
        "  # el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "  X = count_vectorizer.fit_transform([texto_limpio])\n",
        "  print(count_vectorizer.get_feature_names_out())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk4jy4fBtC3p",
        "outputId": "3fba6cf4-0f26-4a04-d72e-e41d11c8fd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el poder reside donde los hombres creen que reside es un truco una sombra en la pared y un hombre muy pequeño puede proyectar una sombra muy grande\n"
          ]
        }
      ],
      "source": [
        "#Convertimos a minusculas\n",
        "texto = texto.lower()\n",
        "print(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-A09EAftDVm",
        "outputId": "1d72a7ed-f744-4c68-c1e5-ff0db701120f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "que es el honor comparado con el amor de una mujer que es el deber comparado con el calor de un hijo recien nacido entre los brazos o el recuerdo de la sonrisa de un hermano aire y palabras aire y palabras solo somos humanos y los dioses nos hicieron para el amor es nuestra mayor gloria y nuestra peor tragedia\n"
          ]
        }
      ],
      "source": [
        "#Eliminar acentos\n",
        "texto1 = unidecode.unidecode(texto)\n",
        "\n",
        "print(texto1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST2RVC56tE-i",
        "outputId": "5eceb732-4fad-4c9a-dadf-5881133ec78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['que', 'es', 'el', 'honor', 'comparado', 'con', 'el', 'amor', 'de', 'una', 'mujer', 'que', 'es', 'el', 'deber', 'comparado', 'con', 'el', 'calor', 'de', 'un', 'hijo', 'recien', 'nacido', 'entre', 'los', 'brazos', 'o', 'el', 'recuerdo', 'de', 'la', 'sonrisa', 'de', 'un', 'hermano', 'aire', 'y', 'palabras', 'aire', 'y', 'palabras', 'solo', 'somos', 'humanos', 'y', 'los', 'dioses', 'nos', 'hicieron', 'para', 'el', 'amor', 'es', 'nuestra', 'mayor', 'gloria', 'y', 'nuestra', 'peor', 'tragedia']\n",
            "['honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia']\n"
          ]
        }
      ],
      "source": [
        "#Eliminamos las stop-words:\n",
        "stop_words = stopwords.words('spanish')\n",
        "palabras = texto1.split(' ')\n",
        "print(palabras)\n",
        "\n",
        "palabras_limpias = [p for p in palabras if p not in stop_words]\n",
        "print(palabras_limpias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQqWQv_EtGuQ",
        "outputId": "293edade-c805-4829-8f49-a09b0ecea27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "honor comparado amor mujer deber comparado calor hijo recien nacido brazos recuerdo sonrisa hermano aire palabras aire palabras solo humanos dioses hicieron amor mayor gloria peor tragedia\n"
          ]
        }
      ],
      "source": [
        "#Unimos el texto\n",
        "texto_limpio = ' '.join(palabras_limpias)\n",
        "print(texto_limpio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aMUED4EtIp8",
        "outputId": "49765fce-81e6-443f-c40a-863c39c199dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "#Bag of words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# el objeto count_vectorizer necesita una lista de textos para funcionar\n",
        "X = count_vectorizer.fit_transform([texto_limpio])\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ewq4SgLtKxo",
        "outputId": "ea35c6d3-8c37-4753-d7fa-726073a07e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aire' 'amor' 'brazos' 'calor' 'comparado' 'deber' 'dioses' 'gloria'\n",
            " 'hermano' 'hicieron' 'hijo' 'honor' 'humanos' 'mayor' 'mujer' 'nacido'\n",
            " 'palabras' 'peor' 'recien' 'recuerdo' 'solo' 'sonrisa' 'tragedia']\n"
          ]
        }
      ],
      "source": [
        "print(count_vectorizer.get_feature_names_out())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
